<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">






  
  
  <link rel="stylesheet" href="/lib/Han/dist/han.min.css?v=3.3">



















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">

<link rel="stylesheet" href="/css/main.css?v=7.1.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.1.2">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/Fein.png?v=7.1.2">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/Fein.png?v=7.1.2">


  <link rel="mask-icon" href="/images/logo.svg?v=7.1.2" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="paper2014年seq2seq的encoder-decoder模型在翻译方面取得SOTA结果以后，Attention机制就被广泛关注。但大多是基于RNN等循环网络来做，Attention只是作为网络结构的巧妙设计出现。但是RNN循环神经网络的缺陷很明显，为了拿到上一个状态的结果，下一个状态只能等待，这样就只能一个step一个step来计算，不能并行化处理。于是，也有了CNN的发挥空间，CNN可">
<meta name="keywords" content="Transformer,Seq2Seq">
<meta property="og:type" content="article">
<meta property="og:title" content="Transformer">
<meta property="og:url" content="https://yanfyang.github.io/2019/07/10/transformer/index.html">
<meta property="og:site_name" content="Fein Yang&#39;s Blog">
<meta property="og:description" content="paper2014年seq2seq的encoder-decoder模型在翻译方面取得SOTA结果以后，Attention机制就被广泛关注。但大多是基于RNN等循环网络来做，Attention只是作为网络结构的巧妙设计出现。但是RNN循环神经网络的缺陷很明显，为了拿到上一个状态的结果，下一个状态只能等待，这样就只能一个step一个step来计算，不能并行化处理。于是，也有了CNN的发挥空间，CNN可">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://yanfyang.github.io/images/201907/selfattentionseq2seq.jpg">
<meta property="og:image" content="https://yanfyang.github.io/images/201907/selfattention.jpg">
<meta property="og:image" content="https://yanfyang.github.io/images/201907/transcalvis.jpg">
<meta property="og:image" content="https://yanfyang.github.io/images/201907/multical.JPG">
<meta property="og:image" content="https://yanfyang.github.io/images/201907/multihead.jpg">
<meta property="og:image" content="https://yanfyang.github.io/images/201907/transformer.jpg">
<meta property="og:updated_time" content="2019-09-05T14:09:48.087Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Transformer">
<meta name="twitter:description" content="paper2014年seq2seq的encoder-decoder模型在翻译方面取得SOTA结果以后，Attention机制就被广泛关注。但大多是基于RNN等循环网络来做，Attention只是作为网络结构的巧妙设计出现。但是RNN循环神经网络的缺陷很明显，为了拿到上一个状态的结果，下一个状态只能等待，这样就只能一个step一个step来计算，不能并行化处理。于是，也有了CNN的发挥空间，CNN可">
<meta name="twitter:image" content="https://yanfyang.github.io/images/201907/selfattentionseq2seq.jpg">





  
  
  <link rel="canonical" href="https://yanfyang.github.io/2019/07/10/transformer/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Transformer | Fein Yang's Blog</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Fein Yang's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">生活杂货铺</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://yanfyang.github.io/2019/07/10/transformer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Fein">
      <meta itemprop="description" content="保持好奇，探索有趣。">
      <meta itemprop="image" content="/images/logo.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Fein Yang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Transformer

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-07-10 22:05:13" itemprop="dateCreated datePublished" datetime="2019-07-10T22:05:13+08:00">2019-07-10</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/读paper/" itemprop="url" rel="index"><span itemprop="name">读paper</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/07/10/transformer/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/07/10/transformer/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
            <span id="/2019/07/10/transformer/" class="leancloud_visitors" data-flag-title="Transformer">
              <span class="post-meta-divider">|</span>
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              
                <span class="post-meta-item-text">阅读次数：</span>
              
                <span class="leancloud-visitors-count"></span>
            </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        <h2 id="paper"><a href="#paper" class="headerlink" title="paper"></a>paper</h2><p>2014年seq2seq的encoder-decoder模型在翻译方面取得SOTA结果以后，Attention机制就被广泛关注。但大多是基于RNN等循环网络来做，Attention只是作为网络结构的巧妙设计出现。<br>但是RNN循环神经网络的缺陷很明显，为了拿到上一个状态的结果，下一个状态只能等待，这样就只能一个step一个step来计算，不能并行化处理。于是，也有了CNN的发挥空间，CNN可以抽取不同长度字词的信息，而且通过加深网络，理论上就能得到任意长度的信息，但是CNN也有一些问题，比如为了拿到长的记忆，网络就必须加深，浅层的网络仍然不能得到长时记忆。<br>2017年，Google的大神发了这篇论文，说原来Attention也可以脱离RNN独自使用，仅仅只用self attention就可以替代RNN、CNN的网络结构来提取信息！而且self attention的结构很简单，用矩阵并行计算的话也就只需要做一堆矩阵相乘就可以，Amazing…<br>论文传送：<a href="https://arxiv.org/pdf/1706.03762v5.pdf" target="_blank" rel="noopener">Attention is all you need | 2017</a></p>
<h2 id="模型基础"><a href="#模型基础" class="headerlink" title="模型基础"></a>模型基础</h2><h3 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self Attention"></a>Self Attention</h3><p>注意力机制是说我们在提取信息的时候一般不会大范围的对全貌平均用力，而是更可能会根据情景焦聚到某一点或者某一片范围内。<br>比如 The animal didn’t across the street, because it was too tried. 当翻译这句话的时候，对于it的翻译就会更希望获取animal的信息，而其他的信息可以弱化。<br>Attention机制就提供了这样的设计，它对于输入会拆分成三部分: query，key和value。<br>Self Attention 的序列到序列模型建立需要做如下步骤，对于序列中的每项输入，也就是每个词：</p>
<ol>
<li>拿这个词的query去和其他词的key进行点乘，得到相似度权重；</li>
<li>将所有的权重进行softmax归一化，就得到了每个词的Attention权重向量；</li>
<li>计算所有词的加权和作为这一步的输出；</li>
</ol>
<p>最终就得到了Self Attention的输出序列，示意图如下，左图为seq2seq框架，中图为Attention计算和输出的具体步骤，出自台大李宏毅教授的课件。右图为有两个词序列的自注意力模型的计算具体过程，出自jalammar的可视化博客。</p>
<div style="float:left;border:solid 1px 000;margin:2px;"><img src="/images/201907/selfattentionseq2seq.jpg" title="Self Attention序列模型框架" width="240" height="400"></div>
<div style="float:left;border:solid 1px 000;margin:2px;"><img src="/images/201907/selfattention.jpg" title="Self Attention每个词的输出计算" width="240" height="400"></div>
<div style="float:left;border:solid 1px 000;margin:2px;"><img src="/images/201907/transcalvis.jpg" title="Self Attention计算可视化" width="240" height="300"></div>
<div style="clear:both;"></div>

<h3 id="Multi-head-Attention"><a href="#Multi-head-Attention" class="headerlink" title="Multi-head Attention"></a>Multi-head Attention</h3><p>多头的注意力模型（忽略翻译的不规范哈），是多个Self Attention各自进行独立计算，然后将结果拼接起来，生成更大的矩阵。当然，如果觉得维度太高，还可以加一层全连接W进行降维。之后的输出就跟单个的Self Attention的过程一样了。<br>Multi-head Attention从注意力的可视化来看，不同的Attention负责抽取序列中不同的特征，比如有些偏重于局部信息，有些可以观察到全局的信息，最后将这些信息融合起来得到更综合的信息特征。<br>体会一下，有些类似于CNN中使用不同的kernel进行叠加抽取不同长度词语的信息，但是CNN中的kernel的大小需要手动设置，比如textCNN中作者用了3,4,5大小的kernel进行叠加，而这里Attention机制可以由模型自主学习，更自动化。<br>过程如下图，左边为模型中单个自注意力的计算，右图为模型中多个自注意力的拼接计算。</p>
<div style="float:left;border:solid 1px 000;margin:5px;"><img src="/images/201907/multical.JPG" title="Multi-head Attention计算" width="280" height="456"></div>
<div style="float:left;border:solid 1px 000;margin:5px;"><img src="/images/201907/multihead.jpg" title="Multi-head Attention集成" width="280" height="456"></div>
<div style="clear:both;"></div>

<h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p>有了多头注意力基础模型，把它加深几层，然后组织到encoder - decoder 的框架中，就变成了Transformer。<br>如下为transformer的结构图，图中灰色的encoder和decoder部分其实都是叠加了6层，Nx=6，论文图中只用一层的结构来示意：<br><img src="/images/201907/transformer.jpg" alt="Transformer"><br>需要注意的是自注意力层中，序列中的词由于是挨个比较，相当于词袋模型，并没有语序的概念。为了加入语序，transformer在词嵌入进入自注意力层之前先加入了位置信息的嵌入，来标记语序。<br>位置信息的嵌入使用固定的正弦余弦函数来生成，目的是为了让经过一定长度之后，相对位置的标记相似。作者解释说同时也使用了训练的方式获得位置嵌入的信息，但发现两者差别不大，那么不如直接用公式来计算，更简便。<br>另外，自注意力模型由于用来替代RNN模型，因此也采用了RNN常用的layer normalization的方法，它在每次进入下一层网络之前先归一化处理。</p>
<h2 id="一些资料和介绍"><a href="#一些资料和介绍" class="headerlink" title="一些资料和介绍"></a>一些资料和介绍</h2><p><a href="https://www.bilibili.com/video/av56239558" target="_blank" rel="noopener">台大李宏毅教授的Transformer视频</a><br><a href="http://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener">Jalammar的Transformer可视化讲解博客</a><br><a href="https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb" target="_blank" rel="noopener">官方Tensor2Tensor的Transformer使用</a></p>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        
          
        
        <div class="post-tags">
          
            <a href="/tags/Transformer/" rel="tag"><i class="fa fa-tag"></i> Transformer</a>
          
            <a href="/tags/Seq2Seq/" rel="tag"><i class="fa fa-tag"></i> Seq2Seq</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/07/06/Adaboost/" rel="next" title="Adaboost小结">
                <i class="fa fa-chevron-left"></i> Adaboost小结
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/logo.png" alt="Fein">
            
              <p class="site-author-name" itemprop="name">Fein</p>
              <div class="site-description motion-element" itemprop="description">保持好奇，探索有趣。</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">10</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">4</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">20</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:feinyang46@gmail.com" title="E-Mail &rarr; mailto:feinyang46@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#paper"><span class="nav-number">1.</span> <span class="nav-text">paper</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型基础"><span class="nav-number">2.</span> <span class="nav-text">模型基础</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Self-Attention"><span class="nav-number">2.1.</span> <span class="nav-text">Self Attention</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Multi-head-Attention"><span class="nav-number">2.2.</span> <span class="nav-text">Multi-head Attention</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Transformer"><span class="nav-number">3.</span> <span class="nav-text">Transformer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#一些资料和介绍"><span class="nav-number">4.</span> <span class="nav-text">一些资料和介绍</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Fein</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>








        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>














  
    
    
  
  <script color="0,255,255" opacity="0.5" zindex="-1" count="99" src="/lib/canvas-nest/canvas-nest.min.js"></script>





  
  









  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script src="/lib/three/three.min.js"></script>

  
  <script src="/lib/three/canvas_lines.min.js"></script>


  


  <script src="/js/utils.js?v=7.1.2"></script>

  <script src="/js/motion.js?v=7.1.2"></script>



  
  


  <script src="/js/affix.js?v=7.1.2"></script>

  <script src="/js/schemes/pisces.js?v=7.1.2"></script>



  
  <script src="/js/scrollspy.js?v=7.1.2"></script>
<script src="/js/post-details.js?v=7.1.2"></script>



  


  <script src="/js/next-boot.js?v=7.1.2"></script>


  

  

  

  
  

<script src="//cdn1.lncld.net/static/js/3.11.1/av-min.js"></script>



<script src="//unpkg.com/valine/dist/Valine.min.js"></script>

<script>
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick';
  guest = guest.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: '05HGOTY785fn5xJS55ra73gI-gzGzoHsz',
    appKey: 'HaPDiqJLDXd2b4xuiQmcOw7n',
    placeholder: '给个评论吧...',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: true,
    lang: 'zh-cn' || 'zh-cn'
  });
</script>




  


  




  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
